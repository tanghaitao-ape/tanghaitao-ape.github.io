{"posts":[{"title":"基于ivector的语种识别","content":"背景 针对某语种进行识别，其主要方案为传统的ivector特征，然后采用SVM进行分类。为了快速搭建基线，采用KaldiKaldiKaldi框架和sklearn.svmsklearn.svmsklearn.svm进行实现。 数据预处理 提前准备好所需要的wav.scp，utt2spk，spk2utt文件。其具体格式如下： wav.scp具体内容为音频名与具体路径的对应关系 utt2spk具体内容为音频名与说话人的对应关系 spk2utt具体内容为说话人与音频名的对应关系 提取mfccmfccmfcc特征 直接调用steps下面已经封装好的sh文件。这里包括生成mfcc、vad和数据矫正会在data目录下生成相应的feats.scp文件，同时还会在exp/make_mfcc下面生成对应的特征。 这里，在mfcc特征提取之前，还有如下操作，它们的作用如下： 预加重：口齿、声带差异，补偿高频 分帧：避免长时语音不稳定性(250ms, 10ms) 加窗：获得短时信号(汉明窗) 语音活动检测：分离噪声和语音信号(能量阈值) MFCCMFCCMFCC：对语种信号辨认能力(40维) 训练UBM，提取ivector特征 UBM 的本质为高斯混合函数，训练它的目的是为了避免由于实验室环境下训练数据不足导致的过拟合，通过统计不同语种的语音分布得到的UBM，能够反映语种的平均特征分布。UBM 的训练是一个参数估计的过程，用大量的背景语种在最大似然准则（Maximum Likelihood，ML）下采用期望最大化算法（Expectation Maximization，EM）训练得到一个与语种无关、通道无关的高斯混合函数。高斯混合函数是由多个高斯概率分布函数的加权和构成的，其分布函数的维度与声学特征的维度一致，每个高斯概率分布函数的权重、均值和方差均由先验数据学习得到。因此，其特点如下： N个高斯分量的权重 每个高斯分量的均值向量和方差向量(1048) 一定程度消除说话人和语种之间的差异 MAP最大自适应 关于每个语种的GMM模型 操作： 各个高斯的权值和其方差对识别性能影响不大 通常只更新均值 i-vector 目前 GMM-UBM 已经成为语种识别技术的标准模型，如果把这个模型扩展成为两个联合模型，即为联合因子分析（Joint Factor Analysis，JFA）模型。其中，两个联合模型分别为具有语种之间差异的语种模型，与相同语种之间信道差异的信道模型。但是，其缺点显而易见，在训练模型时，对于语音数据的需求很苛刻：对同一语种需要多条不同环境下的语音数据，同时，计算量也非常庞大。为区分语种空间与信道空间的方法，采用 i-vector 模型，它弥补了 JFA 对于语音数据依赖性大的缺点。 总变化空间描述语种特征空间，其包含语种的语音信息和信道信息 每段语音 M=m+TwM = m + Tw M=m+Tw 其中，mmm为UBMUBMUBM均值超向量，TTT为总变化空间矩阵CF×RCF \\times RCF×R，w为i−vectori-vectori−vector i−vectori-vectori−vector为符合高斯分布的一维向量1×R1 \\times R1×R 具体代码如下，生成的ivector特征在i-vector下面： 具体形式如下，然后可以根据自己的需求将每个文件对应的ivector提取出来： LDA LDA 的目的是最小化类内语种距离，最大化类间语种距离。通过寻找最能区分各类数据的方向，使得新的特征更具区分性。 最小化类内语种距离，最大化类间语种距离 寻找最能区分开各类语种数据的方向 分类准则(最大化广义瑞利商) 其中，SbS_bSb​为类内协方差矩阵，SwS_wSw​为类间协方差矩阵。具体代码如下： SVM训练和预测 SVM模型特点： 核函数 RBF(核空间映射) 数据不均衡问题（采样，类比平衡） 具体模型示意图如下： 其sklearn实现如下： ","link":"https://tanghaitao-ape.github.io/post/ji-yu-ivector-de-yu-chong-shi-bie/"},{"title":"det(min(L.fst·G.fst))搭建","content":"目的 在HMM模型中，输出通常为三音素。目前，ED模型更受业界欢迎，但其输出基元通常为字符或者字母。为了让ED模型输出时候能引入ngram信息，实现从字到词建模，将生成的wfst文件用于RNNT或LAS输出(on the fly)，需要构建LG.fst网络图。 环境配置 需要sirlm和openfst，为方便起见，直接采用kaldi已安装的包(包含sirlm和openfst)。关于kaldi安装，具体参见https://github.com/tanghaitao-ape/kaldi 导入相关环境变量 搭建语言模型 以中文为例，将一句话进行切词(也可以单个字建模)。文本txt格式如下： 训练3-gram程序如下，默认用古德图灵算法折扣值计算： 这里，word2char.txt格式如下： 最终得到语言模型格式为arpa，其中，最左列为词的对数概率，最右列为词的回退概率。 生成G.fst 利用arpa2fst将arpa语言模型转为二进制格式的G.fst，随机检测，检查FST是否是随机的。如果是，则成功退出。打印最大误差。同时，可以转为可视化文件查看。这里，word.txt格式如下，其中#0为消歧符，用于模型的确定化： 具体程序实现如下： 最终得到的G.fst.txt格式如下： 生成L.fst 和通常建模不同，其目的是建立从词到字的关系，从而用于RNNT或者LAS输出的on the fly计算。因此，不存在歧义一说。lexiconp.txt中词到字概率为1.01.01.0。 这里，character.txt格式如下： 需要注意，对生成L.fst采用fstaddselfloops添加自环。其中，自环的in.list存储character.txt的#0索引，out.list存储word.txt的#0索引。最后，考虑到需要与G.fst作复合计算，对其按olabel排序。具体程序如下： 生成LG.fst 将L.fst和G.fst作复合计算，确定化，最小化，权值前推等处理，得到最终LG.fst。这里，确定化操作极为重要，会消除一个节点对应多个相同ilabel，从而使网络遍历更具有确定性，方便后续二分法遍历(条件：线性递增)。具体代码如下： 注意：虽然lexiconp.txt词到字是一一对应，不存在歧义。但是如果在切词txt时，存在歧义信息，依旧会导致作确定化的时候失败。目前，比较可行的是将每个字单独切开，从而保证字到字的映射100%确定。 可视化 将LG.fst可视化，可先利用fstdraw将其转为dotdotdot文件，然后利用dot转为为pdfpdfpdf。其中，dot依赖graphviz，需提前安好。还需要注意，dot中文显示为乱码，需在dot文件添加相应的字体信息，具体见下列程序edge和node行。目前，发现windowswindowswindows可正常显示，但是linuxlinuxlinux依旧乱码。 结果展示 没有加自环的LG.fst 加自环的LG.fst 可看出，加入自环后引入回退信息。当在某一节点找不到相应ilabel时，会通过#0:&lt;eps&gt;回退到另一个节点，期望从另一个节点找到ilabel所对应的弧。 ","link":"https://tanghaitao-ape.github.io/post/detminlfstgfstda-jian/"},{"title":"ping github.com 失败解决方案","content":"问题解决 使用 ping 检测工具找一个能够 ping 通 github.com 的 IP，检测工具网址如下： http://ping.chinaz.com/github.com 选择一个响应较快的 IP，添加到 C:\\Windows\\System32\\drivers\\etc\\host 文件末尾： 140.82.113.3 github.com 再次检测远程连接，成功。 ","link":"https://tanghaitao-ape.github.io/post/ping-githubcom-shi-bai-jie-jue-fang-an/"},{"title":"基于LC-BLSTM在流式语音识别的应用","content":" 论文链接 问题 语音流式识别(chunk窗)： LSTM效果较差，无右视野 BLSTM效果较好，右视野为整句话 初代：CSC-LSTM，𝑁𝑙+𝑁𝑐+𝑁𝑟𝑁_𝑙 + 𝑁_𝑐+ 𝑁_𝑟Nl​+Nc​+Nr​，相比BLSTM在𝑁𝑙𝑁_𝑙Nl​和𝑁𝑟𝑁_𝑟Nr​部分存在更多计算量 二代：LC-BLSTM， 𝑁𝑐+𝑁𝑟𝑁_𝑐+ 𝑁_𝑟Nc​+Nr​，取消𝑁𝑙𝑁_𝑙Nl​计算量，但是存在𝑁𝑟𝑁_𝑟Nr​ 的计算量。具体详见图1 分析𝑁𝑟𝑁_𝑟Nr​部分发现： 提供𝑁𝑐𝑁_𝑐Nc​前向传播中反向计算的hidden state 第iii层𝑁𝑐𝑁_𝑐Nc​前向传播计算结果为第i+1i+1i+1层提供一部分输入 图1： 音频分为多个chunk 方法 具体详见图2 前向计算 #1~#𝑁_𝑐帧输入到模型中，并将其输出传给下一层 第#𝑁_𝑐帧也会作为下一个chunk 第#1帧 hidden state的初始化 #(N_𝑐+1)~#(𝑁_𝑐+𝑁_𝑟)输入到模型中，结果作为下一层的部分输入 反向计算 初始状态为000，从#(𝑁_𝑐+𝑁_𝑟)~#(𝑁_𝑐+1)输入到模型中，将结果进行输出 利用第#(𝑁_𝑐+1)的hidden state作为#𝑁_𝑐的hidden state初始化 #𝑁_𝑐~#1帧输入到模型中，并将其输出传给下一层 汇总 将前向和反向计算#1~#𝑁_𝑐和#(𝑁_𝑐+1)~#(𝑁_𝑐+𝑁_𝑟)输出进行拼接，然后将前向、反向拼接的结果整合，再作为下一层的输入 当网络层全部计算完，只输出#1~#𝑁_𝑐的结果 图2：LC-BLSTM结构图 基于DNN近似的改进算法 图3：基于DNN近似的LCBLSTM 图4：Pytorch LSTM 接口说明 具体细节说明： 反向传递时，NcN_cNc​帧的hidden state初始化由NrN_rNr​过DNN输出决定 LSTM在pytorch的格式如图4所示。num_layer * num_directions 在每一层的时候结果为1；batch为NrN_rNr​的batch，这里和NcN_cNc​相等；hidden_size需要保证DNN的输出维度和LSTM的映射矩阵维度相等 DNN输出的维度为batch * seq * hidden_size，只需要将seq求平均，从而保证可以将结果作为NcN_cNc​部分LSTM反向传播状态初始化的值 需要注意：只是初始化h0，c0表示LSTM阀值的控制程度，其结果依然用000进行初始化 基于RNN近似的改进算法 图5：基于RNN近似的LCBLSTM 具体细节和DNN相似，不在赘述 具体实现 LC-BLSTM伪代码 输入：特征矩阵xs(batch*length*dim)，Nc，Nr，layers 输出：高层表示ys(batch*length_*dim_) for i in range(0, length, Nc): xs_chunk.append(xs[:, i : i + Nc + Nr]) h0_forward, c0_forward = zeros(1, batch, hidden_size), zeros(1, batch, hidden_size) h0_backward, c0_backward = zeros(1, batch, hidden_size), zeros(1, batch, hidden_size) for i in range(length(xs_chunk)): xs_ = xs_chunk[i] for k in range(layers): xs_forward, h0_forward, c0_forward = lstm_forward[k](xs_, h0_forward, c0_forward) xs_backward, h0_backward, c0_backward = lstm_backward[k](xs_[::-1], h0_backward, c0_backward) xs_ = projection_layer[k](cat(xs_forward, xs_backward[::-1], 1)) ys.append(xs_[:, 0 : Nc]) return ys 基于DNN近似的LC-BLSTM伪代码 输入：特征矩阵xs(batch*length*dim)，Nc，Nr，layers 输出：高层表示ys(batch*length_*dim_) for i in range(0, length, Nc): xs_chunk.append(xs[:, i : i + Nc + Nr]) h0_forward, c0_forward, c0_backward = zeros(1, batch, hidden_size), zeros(1, batch, hidden_size), zeros(1, batch, hidden_size) for i in range(length(xs_chunk)): xs_ = xs_chunk[i] for k in range(layers): xs_forward, h0_forward, c0_forward = lstm_forward[k](xs_[0 : Nc], h0_forward, c0_forward) xs_Nc_Nr = DNN[k](xs_[Nc : Nr]) # dim  hidden_size h0_backward = mean(xs_backward, 1).transpose(0,1) # batch, 1, hidden_size --&gt; 1, batch, hidden_size xs_backward, h0_backward, c0_backward = lstm_backward[k](xs_[0 : Nc], h0_backward, c0_backward) xs_forward = cat(xs_forward, xs_Nc_Nr, 1); xs_backward = cat(xs_backward, xs_Nc_Nr, 1) xs_ = projection_layer[k](cat(xs_forward, xs_backward, 1)) ys.append(xs_[:, 0 : Nc]) return ys 实验 数据集：320-hr Switchboard 表1：右视野WER对比结果 表2：FABDI不同连接方式对比 表3：FABSR节点和target delay对比结果 ","link":"https://tanghaitao-ape.github.io/post/ji-yu-lc-blstm-zai-liu-shi-yu-yin-shi-bie-de-ying-yong/"}]}